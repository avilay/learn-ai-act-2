{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    body {\n",
       "        --vscode-font-family: \"Segoe UI\"\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<style>\n",
    "    body {\n",
    "        --vscode-font-family: \"Segoe UI\"\n",
    "    }\n",
    "</style>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most LLM services support streaming and non-streaming endpoints. In llama-index we can use LLMs in two modes - completion and chat. If I don't specify an LLM, llama-index will use gpt-3.5-turbo from OpenAI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.llms import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# By default this will use the gpt-3.5-turbo model.\n",
    "# This model is in the completion mode. This constructor takes a bunch of other\n",
    "# params like temparature, any other model name, etc.\n",
    "llm = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'llama_index.core.llms.types.CompletionResponse'>\n",
      "a renowned physicist and mathematician known for his theory of relativity and contributions to the field of theoretical physics. He was awarded the Nobel Prize in Physics in 1921 for his explanation of the photoelectric effect. Einstein is considered one of the most influential scientists of the 20th century and his work continues to have a profound impact on our understanding of the universe.\n"
     ]
    }
   ],
   "source": [
    "# Use the non-streaming API\n",
    "resp = llm.complete(\"Albert Eistein is \")\n",
    "print(type(resp))\n",
    "print(resp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `complete` API returns a `CompletionResponse` object that looks like this -\n",
    "```python\n",
    "CompletionResponse(\n",
    "    text='a renowned physicist and mathematician known for his theory of relativity...understanding of the universe.', \n",
    "    additional_kwargs={}, \n",
    "    raw={\n",
    "        'id': 'chatcmpl-9RnUQvoxsMIJhm6cUncZfHj2Y7xxK', \n",
    "        'choices': [\n",
    "            Choice(\n",
    "                finish_reason='stop', \n",
    "                index=0, \n",
    "                logprobs=None, \n",
    "                message=ChatCompletionMessage(\n",
    "                    content='a renowned physicist..understanding of the universe.', \n",
    "                    role='assistant', \n",
    "                    function_call=None, \n",
    "                    tool_calls=None\n",
    "                )\n",
    "            )\n",
    "        ], \n",
    "        'created': 1716412122, \n",
    "        'model': 'gpt-3.5-turbo-0125', \n",
    "        'object': 'chat.completion', \n",
    "        'system_fingerprint': None, \n",
    "        'usage': CompletionUsage(\n",
    "            completion_tokens=74, \n",
    "            prompt_tokens=13, \n",
    "            total_tokens=87\n",
    "        )\n",
    "    }, \n",
    "    delta=None\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object llm_completion_callback.<locals>.wrap.<locals>.wrapped_llm_predict.<locals>.wrapped_gen at 0x172e87990>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use the streaming API\n",
    "resp = llm.stream_complete(\"Albert Eistein is \")\n",
    "resp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I need to call the `.delta` property in the delta object to get the real delta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'llama_index.core.llms.types.CompletionResponse'>\n",
      "<class 'llama_index.core.llms.types.CompletionResponse'>\n",
      "<class 'llama_index.core.llms.types.CompletionResponse'>\n",
      "<class 'llama_index.core.llms.types.CompletionResponse'>\n",
      "<class 'llama_index.core.llms.types.CompletionResponse'>\n",
      "<class 'llama_index.core.llms.types.CompletionResponse'>\n",
      "<class 'llama_index.core.llms.types.CompletionResponse'>\n",
      "<class 'llama_index.core.llms.types.CompletionResponse'>\n",
      "<class 'llama_index.core.llms.types.CompletionResponse'>\n",
      "<class 'llama_index.core.llms.types.CompletionResponse'>\n",
      "<class 'llama_index.core.llms.types.CompletionResponse'>\n",
      "<class 'llama_index.core.llms.types.CompletionResponse'>\n",
      "<class 'llama_index.core.llms.types.CompletionResponse'>\n",
      "<class 'llama_index.core.llms.types.CompletionResponse'>\n",
      "<class 'llama_index.core.llms.types.CompletionResponse'>\n",
      "<class 'llama_index.core.llms.types.CompletionResponse'>\n",
      "<class 'llama_index.core.llms.types.CompletionResponse'>\n",
      "<class 'llama_index.core.llms.types.CompletionResponse'>\n",
      "<class 'llama_index.core.llms.types.CompletionResponse'>\n",
      "<class 'llama_index.core.llms.types.CompletionResponse'>\n",
      "<class 'llama_index.core.llms.types.CompletionResponse'>\n",
      "<class 'llama_index.core.llms.types.CompletionResponse'>\n",
      "<class 'llama_index.core.llms.types.CompletionResponse'>\n",
      "<class 'llama_index.core.llms.types.CompletionResponse'>\n",
      "<class 'llama_index.core.llms.types.CompletionResponse'>\n",
      "<class 'llama_index.core.llms.types.CompletionResponse'>\n",
      "<class 'llama_index.core.llms.types.CompletionResponse'>\n",
      "<class 'llama_index.core.llms.types.CompletionResponse'>\n",
      "<class 'llama_index.core.llms.types.CompletionResponse'>\n",
      "<class 'llama_index.core.llms.types.CompletionResponse'>\n",
      "<class 'llama_index.core.llms.types.CompletionResponse'>\n",
      "<class 'llama_index.core.llms.types.CompletionResponse'>\n",
      "<class 'llama_index.core.llms.types.CompletionResponse'>\n",
      "<class 'llama_index.core.llms.types.CompletionResponse'>\n",
      "<class 'llama_index.core.llms.types.CompletionResponse'>\n",
      "<class 'llama_index.core.llms.types.CompletionResponse'>\n",
      "<class 'llama_index.core.llms.types.CompletionResponse'>\n",
      "<class 'llama_index.core.llms.types.CompletionResponse'>\n",
      "<class 'llama_index.core.llms.types.CompletionResponse'>\n",
      "<class 'llama_index.core.llms.types.CompletionResponse'>\n",
      "<class 'llama_index.core.llms.types.CompletionResponse'>\n",
      "<class 'llama_index.core.llms.types.CompletionResponse'>\n",
      "<class 'llama_index.core.llms.types.CompletionResponse'>\n",
      "<class 'llama_index.core.llms.types.CompletionResponse'>\n",
      "<class 'llama_index.core.llms.types.CompletionResponse'>\n",
      "<class 'llama_index.core.llms.types.CompletionResponse'>\n",
      "<class 'llama_index.core.llms.types.CompletionResponse'>\n",
      "<class 'llama_index.core.llms.types.CompletionResponse'>\n",
      "<class 'llama_index.core.llms.types.CompletionResponse'>\n",
      "<class 'llama_index.core.llms.types.CompletionResponse'>\n",
      "<class 'llama_index.core.llms.types.CompletionResponse'>\n",
      "<class 'llama_index.core.llms.types.CompletionResponse'>\n",
      "<class 'llama_index.core.llms.types.CompletionResponse'>\n",
      "<class 'llama_index.core.llms.types.CompletionResponse'>\n",
      "<class 'llama_index.core.llms.types.CompletionResponse'>\n",
      "<class 'llama_index.core.llms.types.CompletionResponse'>\n",
      "<class 'llama_index.core.llms.types.CompletionResponse'>\n",
      "<class 'llama_index.core.llms.types.CompletionResponse'>\n",
      "<class 'llama_index.core.llms.types.CompletionResponse'>\n",
      "<class 'llama_index.core.llms.types.CompletionResponse'>\n",
      "<class 'llama_index.core.llms.types.CompletionResponse'>\n",
      "<class 'llama_index.core.llms.types.CompletionResponse'>\n",
      "<class 'llama_index.core.llms.types.CompletionResponse'>\n",
      "<class 'llama_index.core.llms.types.CompletionResponse'>\n",
      "<class 'llama_index.core.llms.types.CompletionResponse'>\n",
      "<class 'llama_index.core.llms.types.CompletionResponse'>\n",
      "<class 'llama_index.core.llms.types.CompletionResponse'>\n",
      "<class 'llama_index.core.llms.types.CompletionResponse'>\n",
      "<class 'llama_index.core.llms.types.CompletionResponse'>\n",
      "<class 'llama_index.core.llms.types.CompletionResponse'>\n",
      "<class 'llama_index.core.llms.types.CompletionResponse'>\n",
      "<class 'llama_index.core.llms.types.CompletionResponse'>\n",
      "<class 'llama_index.core.llms.types.CompletionResponse'>\n",
      "<class 'llama_index.core.llms.types.CompletionResponse'>\n",
      "<class 'llama_index.core.llms.types.CompletionResponse'>\n",
      "<class 'llama_index.core.llms.types.CompletionResponse'>\n"
     ]
    }
   ],
   "source": [
    "deltas = []\n",
    "for delta in resp:\n",
    "    print(type(delta))\n",
    "    deltas.append(delta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CompletionResponse(text='a', additional_kwargs={}, raw={'id': 'chatcmpl-9RxqdtX1DMl1ZSMFFRT3xPpGujM7U', 'choices': [Choice(delta=ChoiceDelta(content='a', function_call=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], 'created': 1716451939, 'model': 'gpt-3.5-turbo-0125', 'object': 'chat.completion.chunk', 'system_fingerprint': None}, delta='a')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deltas[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is similar to the non-streaming `CompletionResponse`.\n",
    "```python\n",
    "CompletionResponse(\n",
    "    text='a', \n",
    "    additional_kwargs={}, \n",
    "    raw={\n",
    "        'id': 'chatcmpl-9Rnmk8AjpgTS3cmHTY9hMIwVFlaXR', \n",
    "        'choices': [\n",
    "            Choice(\n",
    "                delta=ChoiceDelta(\n",
    "                    content='a', \n",
    "                    function_call=None, \n",
    "                    role=None, \n",
    "                    tool_calls=None\n",
    "                ), \n",
    "                finish_reason=None, \n",
    "                index=0, \n",
    "                logprobs=None\n",
    "            )\n",
    "        ], \n",
    "        'created': 1716413258, \n",
    "        'model': 'gpt-3.5-turbo-0125', \n",
    "        'object': 'chat.completion.chunk', \n",
    "        'system_fingerprint': None\n",
    "    }, \n",
    "    delta='a'\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CompletionResponse(text='a renowned physicist and mathematician known for his theory of relativity and contributions to the field of theoretical physics. He was awarded the Nobel Prize in Physics in 1921 for his explanation of the photoelectric effect. Einstein is considered one of the most influential scientists of the 20th century and his work continues to have a profound impact on our understanding of the universe.', additional_kwargs={}, raw={'id': 'chatcmpl-9RxqdtX1DMl1ZSMFFRT3xPpGujM7U', 'choices': [Choice(delta=ChoiceDelta(content=None, function_call=None, role=None, tool_calls=None), finish_reason='stop', index=0, logprobs=None)], 'created': 1716451939, 'model': 'gpt-3.5-turbo-0125', 'object': 'chat.completion.chunk', 'system_fingerprint': None}, delta='')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deltas[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is what the last chunk looks like -\n",
    "```python\n",
    "CompletionResponse(\n",
    "    text='a renowned physicist and mathematician..understanding of the universe.', \n",
    "    additional_kwargs={}, \n",
    "    raw={\n",
    "        'id': 'chatcmpl-9Rnmk8AjpgTS3cmHTY9hMIwVFlaXR', \n",
    "        'choices': [\n",
    "            Choice(\n",
    "                delta=ChoiceDelta(\n",
    "                    content=None, \n",
    "                    function_call=None, \n",
    "                    role=None, \n",
    "                    tool_calls=None\n",
    "                ), \n",
    "                finish_reason='stop', \n",
    "                index=0, \n",
    "                logprobs=None\n",
    "            )\n",
    "        ], \n",
    "        'created': 1716413258, \n",
    "        'model': 'gpt-3.5-turbo-0125', \n",
    "        'object': 'chat.completion.chunk', \n",
    "        'system_fingerprint': None\n",
    "    }, \n",
    "    delta=''\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deltas[0]:\n",
      "\n",
      "deltas[1]:\n",
      "a\n",
      "deltas[2]:\n",
      " renowned\n",
      "deltas[3]:\n",
      " physicist\n",
      "deltas[4]:\n",
      " and\n",
      "deltas[5]:\n",
      " mathematic\n",
      "deltas[6]:\n",
      "ian\n",
      "deltas[7]:\n",
      " known\n",
      "deltas[8]:\n",
      " for\n",
      "deltas[9]:\n",
      " his\n",
      "deltas[10]:\n",
      " theory\n",
      "deltas[11]:\n",
      " of\n",
      "deltas[12]:\n",
      " rel\n",
      "deltas[13]:\n",
      "ativity\n",
      "deltas[14]:\n",
      " and\n",
      "deltas[15]:\n",
      " contributions\n",
      "deltas[16]:\n",
      " to\n",
      "deltas[17]:\n",
      " the\n",
      "deltas[18]:\n",
      " field\n",
      "deltas[19]:\n",
      " of\n",
      "deltas[20]:\n",
      " theoretical\n",
      "deltas[21]:\n",
      " physics\n",
      "deltas[22]:\n",
      ".\n",
      "deltas[23]:\n",
      " He\n",
      "deltas[24]:\n",
      " was\n",
      "deltas[25]:\n",
      " awarded\n",
      "deltas[26]:\n",
      " the\n",
      "deltas[27]:\n",
      " Nobel\n",
      "deltas[28]:\n",
      " Prize\n",
      "deltas[29]:\n",
      " in\n",
      "deltas[30]:\n",
      " Physics\n",
      "deltas[31]:\n",
      " in\n",
      "deltas[32]:\n",
      " \n",
      "deltas[33]:\n",
      "192\n",
      "deltas[34]:\n",
      "1\n",
      "deltas[35]:\n",
      " for\n",
      "deltas[36]:\n",
      " his\n",
      "deltas[37]:\n",
      " explanation\n",
      "deltas[38]:\n",
      " of\n",
      "deltas[39]:\n",
      " the\n",
      "deltas[40]:\n",
      " photo\n",
      "deltas[41]:\n",
      "electric\n",
      "deltas[42]:\n",
      " effect\n",
      "deltas[43]:\n",
      ".\n",
      "deltas[44]:\n",
      " Einstein\n",
      "deltas[45]:\n",
      " is\n",
      "deltas[46]:\n",
      " considered\n",
      "deltas[47]:\n",
      " one\n",
      "deltas[48]:\n",
      " of\n",
      "deltas[49]:\n",
      " the\n",
      "deltas[50]:\n",
      " most\n",
      "deltas[51]:\n",
      " influential\n",
      "deltas[52]:\n",
      " scientists\n",
      "deltas[53]:\n",
      " of\n",
      "deltas[54]:\n",
      " the\n",
      "deltas[55]:\n",
      " \n",
      "deltas[56]:\n",
      "20\n",
      "deltas[57]:\n",
      "th\n",
      "deltas[58]:\n",
      " century\n",
      "deltas[59]:\n",
      " and\n",
      "deltas[60]:\n",
      " his\n",
      "deltas[61]:\n",
      " work\n",
      "deltas[62]:\n",
      " continues\n",
      "deltas[63]:\n",
      " to\n",
      "deltas[64]:\n",
      " have\n",
      "deltas[65]:\n",
      " a\n",
      "deltas[66]:\n",
      " profound\n",
      "deltas[67]:\n",
      " impact\n",
      "deltas[68]:\n",
      " on\n",
      "deltas[69]:\n",
      " our\n",
      "deltas[70]:\n",
      " understanding\n",
      "deltas[71]:\n",
      " of\n",
      "deltas[72]:\n",
      " the\n",
      "deltas[73]:\n",
      " universe\n",
      "deltas[74]:\n",
      ".\n",
      "deltas[75]:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i, delta in enumerate(deltas):\n",
    "    print(f\"deltas[{i}]:\")\n",
    "    print(delta.delta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a renowned physicist and mathematician known for his theory of relativity and contributions to the field of theoretical physics. He was awarded the Nobel Prize in Physics in 1921 for his explanation of the photoelectric effect. Einstein is considered one of the most influential scientists of the 20th century."
     ]
    }
   ],
   "source": [
    "resp = llm.stream_complete(\"Albert Eistein is \")\n",
    "for delta in resp:\n",
    "    print(delta.delta, end=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.llms import ChatMessage, OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatResponse(message=ChatMessage(role=<MessageRole.ASSISTANT: 'assistant'>, content='Ahoy matey! Ye can call me Captain Rainbowbeard! Aye, me beard be as colorful as a rainbow, just like me personality! Arrr!', additional_kwargs={}), raw={'id': 'chatcmpl-9Rxqk3PKiaV0nsiwUWRFWrvyRyqFP', 'choices': [Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='Ahoy matey! Ye can call me Captain Rainbowbeard! Aye, me beard be as colorful as a rainbow, just like me personality! Arrr!', role='assistant', function_call=None, tool_calls=None))], 'created': 1716451946, 'model': 'gpt-3.5-turbo-0125', 'object': 'chat.completion', 'system_fingerprint': None, 'usage': CompletionUsage(completion_tokens=34, prompt_tokens=23, total_tokens=57)}, delta=None, additional_kwargs={})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# In chat mode, instead of just passing a string as input, we need to pass in a list of chat messages\n",
    "messages = [\n",
    "    ChatMessage(\n",
    "        role=\"system\",\n",
    "        content=\"You are a pirate with a colorful personality\"\n",
    "    ),\n",
    "    ChatMessage(\n",
    "        role=\"user\",\n",
    "        content=\"What is your name\"\n",
    "    )\n",
    "]\n",
    "\n",
    "# I still use the same model, except I call the chat method instead of invoking the model directly.\n",
    "resp = llm.chat(messages)\n",
    "resp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of `CompletionResponse`, this API returns an object of type `ChatResponse`.\n",
    "```python\n",
    "ChatResponse(\n",
    "    message=ChatMessage(\n",
    "        role=<MessageRole.ASSISTANT: 'assistant'>, \n",
    "        content=\"Ahoy matey! The name's Captain Rainbowbeard! Aye...me hearty?\", \n",
    "        additional_kwargs={}\n",
    "    ), \n",
    "    raw={\n",
    "        'id': 'chatcmpl-9RnxfUqEgwaXk6SMlvTtt2em95cQO', \n",
    "        'choices': [\n",
    "            Choice(\n",
    "                finish_reason='stop', \n",
    "                index=0, \n",
    "                logprobs=None, \n",
    "                message=ChatCompletionMessage(\n",
    "                    content=\"Ahoy matey!...me hearty?\", \n",
    "                    role='assistant', \n",
    "                    function_call=None, \n",
    "                    tool_calls=None\n",
    "                )\n",
    "            )\n",
    "        ], \n",
    "        'created': 1716413935, \n",
    "        'model': 'gpt-3.5-turbo-0125', \n",
    "        'object': 'chat.completion', \n",
    "        'system_fingerprint': None, \n",
    "        'usage': CompletionUsage(\n",
    "            completion_tokens=63, \n",
    "            prompt_tokens=23, \n",
    "            total_tokens=86\n",
    "        )\n",
    "    }, \n",
    "    delta=None, \n",
    "    additional_kwargs={}\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "assistant: Ahoy matey! Ye can call me Captain Rainbowbeard! Aye, me beard be as colorful as a rainbow, just like me personality! Arrr!\n"
     ]
    }
   ],
   "source": [
    "print(resp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
