{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quickstart 2\n",
    "Demo the use of output parsers.\n",
    "\n",
    "Lets say that given a customer review, I want the LLM to output some information,but it should be in JSON format.\n",
    "\n",
    "```json\n",
    "{\n",
    "  \"gift\": False,\n",
    "  \"delivery_days\": 5,\n",
    "  \"price_value\": \"pretty affordable!\"\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_community.chat_models import ChatOllama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_prompt(prompt_template, **kwargs):\n",
    "    prompt_template = ChatPromptTemplate.from_template(prompt_template)\n",
    "    prompts = prompt_template.format_messages(**kwargs)\n",
    "    return prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def complete(llm, prompts):\n",
    "    return llm.invoke(prompts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For the following text, extract the following information:\n",
      "\n",
      "gift: Was the item purchased as a gift for someone else? Answer True if yes, False if not or unknown.\n",
      "\n",
      "delivery_days: How many days did it take for the product to arrive? If this information is not found, output -1.\n",
      "\n",
      "price_value: Extract any sentences about the value or price,and output them as a comma separated Python list.\n",
      "\n",
      "Format the output as JSON with the following keys:\n",
      "gift\n",
      "delivery_days\n",
      "price_value\n",
      "\n",
      "text: This leaf blower is pretty amazing.  It has four settings:candle blower, gentle breeze, windy city, and tornado. It arrived in two days, just in time for my wife's anniversary present. I think my wife liked it so much she was speechless. So far I've been the only one using it, and I've been using it every other morning to clear the leaves on our lawn. It's slightly more expensive than the other leaf blowers out there, but I think it's worth it for the extra features.\n"
     ]
    }
   ],
   "source": [
    "prompt_template = \"\"\"For the following text, extract the following information:\n",
    "\n",
    "gift: Was the item purchased as a gift for someone else? Answer True if yes, False if not or unknown.\n",
    "\n",
    "delivery_days: How many days did it take for the product to arrive? If this information is not found, output -1.\n",
    "\n",
    "price_value: Extract any sentences about the value or price,and output them as a comma separated Python list.\n",
    "\n",
    "Format the output as JSON with the following keys:\n",
    "gift\n",
    "delivery_days\n",
    "price_value\n",
    "\n",
    "text: {text}\"\"\"\n",
    "\n",
    "customer_review = \"\"\"This leaf blower is pretty amazing.  It has four settings:candle blower, gentle breeze, windy city, and tornado. It arrived in two days, just in time for my wife's anniversary present. I think my wife liked it so much she was speechless. So far I've been the only one using it, and I've been using it every other morning to clear the leaves on our lawn. It's slightly more expensive than the other leaf blowers out there, but I think it's worth it for the extra features.\"\"\"\n",
    "\n",
    "prompts = build_prompt(prompt_template, text= customer_review)\n",
    "print(prompts[0].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{\n",
      "\"gift\": True,\n",
      "\"delivery_days\": 2,\n",
      "\"price_value\": [\"slightly more expensive than the other leaf blowers out there\", \"worth it for the extra features\"]\n",
      "}\n",
      "\n",
      "\n",
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "llama2 = ChatOllama(model=\"llama2\", temperature=0)\n",
    "completion = complete(llama2, prompts)\n",
    "print(completion.content)\n",
    "print(\"\\n\")\n",
    "print(type(completion.content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"gift\": false,\n",
      "  \"delivery_days\": 2,\n",
      "  \"price_value\": [\"It's slightly more expensive than the other leaf blowers out there, but I think it's worth it for the extra features.\"]\n",
      "}\n",
      "\n",
      "\n",
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "gpt = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)  #type: ignore\n",
    "completion = complete(gpt, prompts)\n",
    "print(completion.content)\n",
    "print(\"\\n\")\n",
    "print(type(completion.content))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even though the above output looks like JSON, it is just a plain old string. I cannot use it programmatically. In order to get a real JSON out of the answer, I can use LangChain's output parsers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.output_parsers import ResponseSchema\n",
    "from langchain.output_parsers import StructuredOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_format_instructions(gift, delivery_days, price_value):\n",
    "    output_parser = StructuredOutputParser.from_response_schemas([\n",
    "        gift, delivery_days, price_value\n",
    "    ])\n",
    "    return output_parser, output_parser.get_format_instructions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For the following text, extract the following information:\n",
      "\n",
      "gift: Was the item purchased as a gift for someone else? Answer True if yes, False if not or unknown.\n",
      "\n",
      "delivery_days: How many days did it take for the product to arrive? If this information is not found, output -1.\n",
      "\n",
      "price_value: Extract any sentences about the value or price,and output them as a comma separated Python list.\n",
      "\n",
      "text: This leaf blower is pretty amazing.  It has four settings:candle blower, gentle breeze, windy city, and tornado. It arrived in two days, just in time for my wife's anniversary present. I think my wife liked it so much she was speechless. So far I've been the only one using it, and I've been using it every other morning to clear the leaves on our lawn. It's slightly more expensive than the other leaf blowers out there, but I think it's worth it for the extra features.\n",
      "\n",
      "The output should be a markdown code snippet formatted in the following schema, including the leading and trailing \"```json\" and \"```\":\n",
      "\n",
      "```json\n",
      "{\n",
      "\t\"gift\": string  // Was the item purchased as a gift for someone else? Answer True if yes, False if not or unknown.\n",
      "\t\"delivery_days\": string  // How many days did it take for the product to arrive? If this information is not found, output -1.\n",
      "\t\"price_value\": string  // Extract any sentences about the value or price and output them as a comma separated Python list.\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "prompt_template = \"\"\"For the following text, extract the following information:\n",
    "\n",
    "gift: Was the item purchased as a gift for someone else? Answer True if yes, False if not or unknown.\n",
    "\n",
    "delivery_days: How many days did it take for the product to arrive? If this information is not found, output -1.\n",
    "\n",
    "price_value: Extract any sentences about the value or price,and output them as a comma separated Python list.\n",
    "\n",
    "text: {text}\n",
    "\n",
    "{format_instructions}\"\"\"\n",
    "\n",
    "\n",
    "gift = ResponseSchema(\n",
    "    name=\"gift\",\n",
    "    description=\"Was the item purchased as a gift for someone else? Answer True if yes, False if not or unknown.\")\n",
    "\n",
    "delivery_days = ResponseSchema(\n",
    "    name=\"delivery_days\",\n",
    "    description=\"How many days did it take for the product to arrive? If this information is not found, output -1.\")\n",
    "\n",
    "price_value = ResponseSchema(\n",
    "    name=\"price_value\",\n",
    "    description=\"Extract any sentences about the value or price and output them as a comma separated Python list.\")\n",
    "\n",
    "parser, format_instructions = build_format_instructions(gift, delivery_days, price_value)\n",
    "\n",
    "prompts = build_prompt(prompt_template, text=customer_review, format_instructions=format_instructions)\n",
    "\n",
    "print(prompts[0].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sure! Here's the extracted information in JSON format:\n",
      "```json\n",
      "{\n",
      "    \"gift\": True,\n",
      "    \"delivery_days\": \"2\",\n",
      "    \"price_value\": [\"pretty amazing\", \"slightly more expensive than the other leaf blowers out there\", \"worth it for the extra features\"]\n",
      "}\n",
      "```\n",
      "Explanation:\n",
      "\n",
      "* `gift`: Yes, the item was purchased as a gift for someone else.\n",
      "* `delivery_days`: The product arrived in 2 days.\n",
      "* `price_value`: The sentences about the value or price of the leaf blower are \"pretty amazing\", \"slightly more expensive than the other leaf blowers out there\", and \"worth it for the extra features\". These are separated by commas because they are a list of values.\n",
      "\n",
      "\n",
      "<class 'str'>\n",
      "\n",
      "\n",
      "Got invalid JSON object. Error: Expecting value: line 2 column 13 (char 14)\n",
      "Notice that LLAMA-2 outputted incorrect JSON, with boolean value as `True` instead of `true`.\n"
     ]
    }
   ],
   "source": [
    "llama2 = ChatOllama(model=\"llama2\", temperature=0)\n",
    "completion = complete(llama2, prompts)\n",
    "print(completion.content)\n",
    "print(\"\\n\")\n",
    "print(type(completion.content))\n",
    "print(\"\\n\")\n",
    "try:\n",
    "    parser.parse(completion.content)  #type: ignore\n",
    "except Exception as err:\n",
    "    print(err)\n",
    "    print(\"Notice that LLAMA-2 outputted incorrect JSON, with boolean value as `True` instead of `true`.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```json\n",
      "{\n",
      "\t\"gift\": false,\n",
      "\t\"delivery_days\": \"2\",\n",
      "\t\"price_value\": \"It's slightly more expensive than the other leaf blowers out there, but I think it's worth it for the extra features.\"\n",
      "}\n",
      "```\n",
      "\n",
      "\n",
      "<class 'str'>\n",
      "\n",
      "\n",
      "<class 'dict'>\n",
      "\n",
      "\n",
      "{'gift': False, 'delivery_days': '2', 'price_value': \"It's slightly more expensive than the other leaf blowers out there, but I think it's worth it for the extra features.\"}\n"
     ]
    }
   ],
   "source": [
    "gpt = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)  #type: ignore\n",
    "completion = complete(gpt, prompts)\n",
    "print(completion.content)\n",
    "print(\"\\n\")\n",
    "print(type(completion.content))\n",
    "print(\"\\n\")\n",
    "json_content = parser.parse(completion.content)  #type: ignore\n",
    "print(type(json_content))\n",
    "print(\"\\n\")\n",
    "print(json_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
