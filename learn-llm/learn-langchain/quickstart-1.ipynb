{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_community.chat_models import ChatOllama\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_email = \"\"\"Arrr, I be fuming that me blender lid flew off and splattered me kitchen walls with smoothie! And to make matters worse,the warranty don't cover the cost of cleaning up me kitchen. I need yer help right now, matey!\"\"\"\n",
    "\n",
    "style = \"American English in a calm and respectful tone\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['style', 'text'], messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['style', 'text'], template='Translate the text that is delimited by triple backticks into a style that is {style}.\\ntext: ```{text}```'))])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_template = ChatPromptTemplate.from_template(\"\"\"Translate the text that is delimited by triple backticks into a style that is {style}.\n",
    "text: ```{text}```\"\"\"\n",
    ")\n",
    "prompt_template"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "ChatPromptTemplate(\n",
    "    input_variables=['style', 'text'], \n",
    "    messages=[\n",
    "        HumanMessagePromptTemplate(\n",
    "            prompt=PromptTemplate(\n",
    "                input_variables=['style', 'text'],template='Translate the text that is delimited by triple backticks into a style that is {style}.\\ntext: ```{text}```'\n",
    "            )\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translate the text that is delimited by triple backticks into a style that is {style}.\n",
      "text: ```{text}```\n"
     ]
    }
   ],
   "source": [
    "print(prompt_template.messages[0].prompt.template)  #type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translate the text that is delimited by triple backticks into a style that is American English in a calm and respectful tone.\n",
      "text: ```Arrr, I be fuming that me blender lid flew off and splattered me kitchen walls with smoothie! And to make matters worse,the warranty don't cover the cost of cleaning up me kitchen. I need yer help right now, matey!```\n"
     ]
    }
   ],
   "source": [
    "prompts = prompt_template.format_messages(style=style, text=customer_email)\n",
    "print(prompts[0].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    del prompt_template\n",
    "    del prompts\n",
    "    del customer_email\n",
    "    del style\n",
    "except NameError:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_prompt(prompt_template, customer_email, style):\n",
    "    prompt_template = ChatPromptTemplate.from_template(prompt_template)\n",
    "    prompts = prompt_template.format_messages(style=style, text=customer_email)\n",
    "    return prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def complete(llm, prompts):\n",
    "    return llm.invoke(prompts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translate the text that is delimited by triple backticks into a style that is American English in a calm and respectful tone.\n",
      "text: ```Arrr, I be fuming that me blender lid flew off and splattered me kitchen walls with smoothie! And to make matters worse,the warranty don't cover the cost of cleaning up me kitchen. I need yer help right now, matey!```\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prompt_template = \"\"\"Translate the text that is delimited by triple backticks into a style that is {style}.\n",
    "text: ```{text}```\n",
    "\"\"\"\n",
    "\n",
    "customer_email = \"\"\"Arrr, I be fuming that me blender lid flew off and splattered me kitchen walls with smoothie! And to make matters worse,the warranty don't cover the cost of cleaning up me kitchen. I need yer help right now, matey!\"\"\"\n",
    "\n",
    "style = \"American English in a calm and respectful tone\"\n",
    "\n",
    "prompts = build_prompt(prompt_template, customer_email, style)\n",
    "print(prompts[0].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Oh my goodness, that's quite an inconvenience you're facing there, matey! ðŸ˜³ I can totally understand why ye be fumin' about the blender lid flyin' off and makin' a mess of yer kitchen. ðŸ¤¯ And to top it all off, ye don't have the warranty coverin' the cost of cleanin' up the mess?! ðŸ˜”\\n\\nBut never fear, me hearty! I be here to help ye out. Let's see if we can figure out a way to get that smoothie stain off yer walls, shall we? Mayhap a good scrubbin' with some soap and water will do the trick? Or mayhap there be a special cleanin' solution for gettin' rid of smoothie stains? ðŸ¤”\\n\\nAnd as fer the warranty, why don't ye give me a holler and I'll see if I can help ye figure out what yer options be? Mayhap there be somethin' we can do to get that covered for ye. ðŸ˜Š\\n\\nSo don't ye worry yerself, matey! We'll get through this together, savvy? ðŸ˜Š\")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llama2 = ChatOllama(model=\"llama2\", temperature=0)\n",
    "customer = complete(llama2, prompts)\n",
    "customer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Oh my goodness, that's quite an inconvenience you're facing there, matey! ðŸ˜³ I can totally understand why ye be fumin' about the blender lid flyin' off and makin' a mess of yer kitchen. ðŸ¤¯ And to top it all off, ye don't have the warranty coverin' the cost of cleanin' up the mess?! ðŸ˜”\n",
      "\n",
      "But never fear, me hearty! I be here to help ye out. Let's see if we can figure out a way to get that smoothie stain off yer walls, shall we? Mayhap a good scrubbin' with some soap and water will do the trick? Or mayhap there be a special cleanin' solution for gettin' rid of smoothie stains? ðŸ¤”\n",
      "\n",
      "And as fer the warranty, why don't ye give me a holler and I'll see if I can help ye figure out what yer options be? Mayhap there be somethin' we can do to get that covered for ye. ðŸ˜Š\n",
      "\n",
      "So don't ye worry yerself, matey! We'll get through this together, savvy? ðŸ˜Š\n"
     ]
    }
   ],
   "source": [
    "print(customer.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Arrr, I'm quite upset that my blender lid flew off and splattered my kitchen walls with smoothie! And to make matters worse, the warranty doesn't cover the cost of cleaning up my kitchen. I kindly request your assistance at this moment, matey!\")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpt = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)  #type: ignore\n",
    "customer = complete(gpt, prompts)\n",
    "customer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arrr, I'm quite upset that my blender lid flew off and splattered my kitchen walls with smoothie! And to make matters worse, the warranty doesn't cover the cost of cleaning up my kitchen. I kindly request your assistance at this moment, matey!\n"
     ]
    }
   ],
   "source": [
    "print(customer.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translate the text that is delimited by triple backticks into a style that is a polite tone that speaks in English Pirate.\n",
      "text: ```Hey there customer, the warranty does not cover cleaning expenses for your kitchen because it's your fault that you misused your blender by forgetting to put the lid on before starting the blender. Tough luck! See ya!```\n",
      "\n"
     ]
    }
   ],
   "source": [
    "reply_email = \"\"\"Hey there customer, the warranty does not cover cleaning expenses for your kitchen because it's your fault that you misused your blender by forgetting to put the lid on before starting the blender. Tough luck! See ya!\"\"\"\n",
    "\n",
    "style = \"a polite tone that speaks in English Pirate\"\n",
    "\n",
    "prompts = build_prompt(prompt_template, reply_email, style)\n",
    "print(prompts[0].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Arrrr, matey! Here be the translation o' yer text into a polite tone speakin' like a proper English Pirate:\n",
      "\n",
      "\"Ahoy there, customer! Yer warranty don't cover cleanin' costs fer yer kitchen, savvy? It be yer own fault fer forgettin' ta put the lid on yer blender afore startin' it. Shucks, matey! See yeh later!\"\n"
     ]
    }
   ],
   "source": [
    "reply = complete(llama2, prompts)\n",
    "print(reply.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ahoy there, matey! I be sorry to inform ye, but the warranty be not coverin' the expenses o' cleanin' yer galley, as 'tis yer own fault fer misusin' yer blender by forgettin' to put the lid on afore startin' it. Aye, tough luck! Fare thee well, me heartie!\n"
     ]
    }
   ],
   "source": [
    "reply = complete(gpt, prompts)\n",
    "print(reply.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
