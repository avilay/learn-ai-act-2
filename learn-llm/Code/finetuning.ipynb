{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "from pathlib import Path\n",
    "\n",
    "import torch as t\n",
    "import wandb as wb\n",
    "from datasets import load_dataset\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from transformers import AutoTokenizer\n",
    "from dataclasses import dataclass, asdict\n",
    "\n",
    "import evaluate\n",
    "from tqdm.auto import tqdm\n",
    "from transformers import AutoModelForSequenceClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = \"bert-base-uncased\"\n",
    "DEVICE = t.device(\"mps\")\n",
    "DATAROOT = Path.home()/\"mldata\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Hyperparams:\n",
    "    n_epochs: int\n",
    "    batch_size: int\n",
    "    lr: float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate(tokenizer, xs):\n",
    "    \"\"\"\n",
    "    List of instances, where each instance is a dict that looks like -\n",
    "    {\n",
    "        \"sentence1\": <sentence here>,\n",
    "        \"sentence2\": <sentence here>,\n",
    "        \"label\": 0,\n",
    "        \"idx\": 1\n",
    "    }\n",
    "    \"\"\"\n",
    "    s1s, s2s, labels = [], [], []\n",
    "    for x in xs:\n",
    "        s1s.append(x[\"sentence1\"])\n",
    "        s2s.append(x[\"sentence2\"])\n",
    "        labels.append(x[\"label\"])\n",
    "\n",
    "    batch = tokenizer(s1s, s2s, truncation=True, padding=True, return_tensors=\"pt\")\n",
    "    batch[\"labels\"] = t.tensor(labels)\n",
    "    return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataloaders(train_batch_size, eval_batch_size):\n",
    "    mrpc = load_dataset(\"glue\", \"mrpc\")\n",
    "    tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "    collate_fn = partial(collate, tokenizer)\n",
    "\n",
    "    traindl = DataLoader(\n",
    "        mrpc[\"train\"],\n",
    "        shuffle=True, \n",
    "        batch_size=train_batch_size, \n",
    "        collate_fn=collate_fn\n",
    "    )\n",
    "    valdl = DataLoader(\n",
    "        mrpc[\"validation\"],\n",
    "        shuffle=False,\n",
    "        batch_size=eval_batch_size,\n",
    "        collate_fn=collate_fn,\n",
    "    )\n",
    "    testdl = DataLoader(\n",
    "        mrpc[\"test\"], \n",
    "        shuffle=False, \n",
    "        batch_size=eval_batch_size, \n",
    "        collate_fn=collate_fn\n",
    "    )\n",
    "    return traindl, valdl, testdl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval(model, valdl, global_step):\n",
    "    metric = evaluate.load(\"glue\", \"mrpc\")\n",
    "    losses = []\n",
    "    model.eval()\n",
    "    for batch in tqdm(valdl):\n",
    "        batch = {k: v.to(DEVICE) for k, v in batch.items()}\n",
    "        with t.no_grad():\n",
    "            outputs = model(**batch)\n",
    "        losses.append(outputs.loss.item())\n",
    "        logits = outputs.logits\n",
    "        predictions = t.argmax(logits, dim=-1)\n",
    "        metric.add_batch(predictions=predictions, references=batch[\"labels\"])\n",
    "    eval_metrics = metric.compute()\n",
    "    avg_loss = t.mean(t.tensor(losses)).item()\n",
    "    wb.log(\n",
    "        {\n",
    "            \"val/accuracy\": eval_metrics[\"accuracy\"],\n",
    "            \"val/F1\": eval_metrics[\"f1\"],\n",
    "            \"val/loss\": avg_loss\n",
    "        },\n",
    "        step=global_step\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, traindl, global_step, optim, lr_scheduler):\n",
    "    metric = evaluate.load(\"glue\", \"mrpc\")\n",
    "    batch_losses = []\n",
    "    model.train()\n",
    "    with t.enable_grad():\n",
    "        for batch in tqdm(traindl):\n",
    "            batch = {k: v.to(DEVICE) for k, v in batch.items()}\n",
    "            \n",
    "            optim.zero_grad()\n",
    "            outputs = model(**batch)\n",
    "            loss = outputs.loss\n",
    "            loss.backward()\n",
    "            optim.step()\n",
    "            lr_scheduler.step()\n",
    "\n",
    "            preds = t.argmax(outputs.logits, dim=-1)\n",
    "            metric.add_batch(predictions=preds, references=batch[\"labels\"])\n",
    "            batch_losses.append(loss.detach().item())\n",
    "\n",
    "            global_step += 1\n",
    "        \n",
    "    epoch_loss = t.mean(t.tensor(batch_losses))\n",
    "    train_metrics = metric.compute()\n",
    "    wb.log(\n",
    "        {\n",
    "            \"loss/train\": epoch_loss.item(),\n",
    "            \"accuracy/train\": train_metrics[\"accuracy\"],\n",
    "            \"f1/train\": train_metrics[\"f1\"]\n",
    "        },\n",
    "        step=global_step\n",
    "    )\n",
    "    return global_step\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/avilay/projects/bitbucket/learn/learn-ai/act2/learn-llm/Code/wandb/run-20231228_164802-bmqsb009</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/avilay/finetune-mrpc/runs/bmqsb009' target=\"_blank\">lilac-voice-6</a></strong> to <a href='https://wandb.ai/avilay/finetune-mrpc' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/avilay/finetune-mrpc' target=\"_blank\">https://wandb.ai/avilay/finetune-mrpc</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/avilay/finetune-mrpc/runs/bmqsb009' target=\"_blank\">https://wandb.ai/avilay/finetune-mrpc/runs/bmqsb009</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb6df12c9fe14c82ba70b067c2b00bdc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/459 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7087517979984233b9f418d718074cb5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/51 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88d333047c4c4f2289b149c5a4570c7e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/459 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "python(15093) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(15119) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(15150) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(15168) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(15178) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(15214) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(15222) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(15246) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(15249) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(15251) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(15257) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(15266) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(15271) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(15273) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(15276) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(15280) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(15294) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(15299) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(15301) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(15347) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(15351) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(15381) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(15405) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(15409) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(15416) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(15420) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(15424) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(15439) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(15449) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(15482) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(15537) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(15560) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(15562) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(15602) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(15622) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(15637) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(15661) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(15678) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(15694) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(15704) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(15712) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(15717) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(15727) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(15735) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd9bf7b15e244a88ae61b78928263dda",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/51 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "python(15746) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(15764) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67c435a613b941b5b9e334299bedc1fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/459 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "python(15775) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(15820) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(15834) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(15839) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(15842) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(15858) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(15861) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(15864) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(15870) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(15871) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(15874) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(15878) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(15892) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(15893) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(15895) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(15933) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(15953) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(15957) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(15958) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(15963) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(15974) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(15989) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(16007) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(16025) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(16045) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(16056) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(16060) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(16081) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(16095) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(16123) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(16143) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(16153) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(16160) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(16163) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(16168) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(16174) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(16211) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(16215) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(16221) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(16225) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a044e9ebbfc14f4a91f56f4a1d379e06",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/51 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "python(16242) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "wandb: WARNING Source type is set to 'repo' but some required information is missing from the environment. A job will not be created from this run. See https://docs.wandb.ai/guides/launch/create-job\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35a23a9df5444495b972ac76bf7a12c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy/train</td><td>▁▅█</td></tr><tr><td>f1/train</td><td>▁▅█</td></tr><tr><td>loss/train</td><td>█▄▁</td></tr><tr><td>val/F1</td><td>█▁▇</td></tr><tr><td>val/accuracy</td><td>█▁▆</td></tr><tr><td>val/loss</td><td>▇▁█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy/train</td><td>0.9452</td></tr><tr><td>f1/train</td><td>0.95934</td></tr><tr><td>loss/train</td><td>0.14761</td></tr><tr><td>val/F1</td><td>0.88235</td></tr><tr><td>val/accuracy</td><td>0.83333</td></tr><tr><td>val/loss</td><td>0.43604</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">lilac-voice-6</strong> at: <a href='https://wandb.ai/avilay/finetune-mrpc/runs/bmqsb009' target=\"_blank\">https://wandb.ai/avilay/finetune-mrpc/runs/bmqsb009</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20231228_164802-bmqsb009/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "hparams = Hyperparams(n_epochs=3, batch_size=8, lr=5e-5)\n",
    "\n",
    "run = wb.init(\n",
    "    project=\"finetune-mrpc\",\n",
    "    config=asdict(hparams)\n",
    ")\n",
    "\n",
    "traindl, valdl, testdl = dataloaders(hparams.batch_size, hparams.batch_size)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME, num_labels=2)\n",
    "model.to(DEVICE)\n",
    "optim = t.optim.AdamW(model.parameters(), lr=hparams.lr)\n",
    "num_training_steps = hparams.n_epochs * len(traindl)\n",
    "lr_scheduler = t.optim.lr_scheduler.LinearLR(optimizer=optim, start_factor=1., end_factor=0.3, total_iters=num_training_steps)\n",
    "\n",
    "wb.watch(model.classifier, log=\"all\", log_freq=100)\n",
    "\n",
    "global_step = 1\n",
    "for epoch in range(hparams.n_epochs):\n",
    "    global_step = train(model, traindl, global_step, optim, lr_scheduler)\n",
    "    eval(model, valdl, global_step)\n",
    "\n",
    "wb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d79c06e3f5c0464cb1210e2214fd2976",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: WARNING Source type is set to 'repo' but some required information is missing from the environment. A job will not be created from this run. See https://docs.wandb.ai/guides/launch/create-job\n"
     ]
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">happy-frost-5</strong> at: <a href='https://wandb.ai/avilay/finetune-mrpc/runs/6qovy7rl' target=\"_blank\">https://wandb.ai/avilay/finetune-mrpc/runs/6qovy7rl</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20231228_164459-6qovy7rl/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
